<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Nhat Truong Pham </title> <meta name="author" content="Nhat Truong Pham"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/icon.png?1e5a7fb652b1868ab49bdd3c8fe588a6"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://nhattruongpham.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">Home <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">News </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/collaborators/">Collaborators </a> </li> <li class="nav-item "> <a class="nav-link" href="/mentees/">Mentees </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Tools </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/molecules/">Molecules</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/dna/">DNA</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/rna/">RNA</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/peptide/">Peptide</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/protein/">Protein</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/microbiome/">Microbiome</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/imaging/">Imaging</a> </div> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Gallery </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/skkurs24/">SKKU-RS-24</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/ijcai24/">IJCAI-24</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/acl24/">ACL-24</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/aita25/">AiTA-25</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/bpsam25/">BPS-AM-25</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/aitacbbl25/">AiTA-CBBL-25</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/acsnanom25/">ACS-Nano-AEM-25</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/isaac25/">ISAAC-25</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Nhat Truong</span> Pham </h1> <p class="desc">Ph.D. Candidate in Integrative Biotechnology specializing in üß¨Applied Machine Learning/Deep Learning for Computational Biology and Bioinformaticsüß¨</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/profile_since_2024.png" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/profile_since_2024.png?e213cb3176c3926e8e8e66f33fcf1b23" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="profile_since_2024.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p>Room 62105, Biotechnology and Bioengineering Building 2, Seobu-ro, Jangan-gu, Suwon-si, Gyeonggi-do, 16419, Republic of Korea</p> </div> </div> <div class="clearfix"> <p><strong>Short Bio:</strong> My name is <i>Ph·∫°m Nh·∫≠t Tr∆∞·ªùng</i> - Vietnamese (ENG: Nhat Truong Pham; CHN: ËåÉÊó•Èïø; KOR: Î≤îÏùºÏû•). I am currently a <del>first/second</del>/third-year Ph.D. <del>Student</del>/Candidate at the <a href="https://skb.skku.edu/eng_gene/index.do" rel="external nofollow noopener" target="_blank">Department of Integrative Biotechnology</a>, <a href="https://biotech.skku.edu/eng_biotech/index.do" rel="external nofollow noopener" target="_blank">College of Biotechnology and Bioengineering</a>, <a href="https://www.skku.edu/eng/" rel="external nofollow noopener" target="_blank">Sungkyunkwan University (SKKU)</a>, Republic of Korea. I am working under the guidance of Associate Professor <a href="https://skb.skku.edu/eng_gene/faculty.do?mode=view&amp;perId=LZStrB4DgrAqgzgNgwgGQCwGkAuArAigEQE4BCA5gHYBmMAnkQLw1A" rel="external nofollow noopener" target="_blank">Balachandran Manavalan</a> in the <a href="https://balalab-skku.org/" rel="external nofollow noopener" target="_blank">Computational Biology and Bioinformatics Laboratory</a>. Prior to joining SKKU, I have worked as an Assistant Researcher at <a href="https://tdtu.edu.vn/en" rel="external nofollow noopener" target="_blank">Ton Duc Thang University (TDTU)</a>, Vietnam. I completed my M.E. degree in Automation and Control at TDTU, where I was supervised by Dr. <a href="https://sites.google.com/view/nguyensydzung" rel="external nofollow noopener" target="_blank">Sy Dzung Nguyen</a> and co-supervised by Associate Professor <a href="https://dnmduc.github.io/" rel="external nofollow noopener" target="_blank">Duc Ngoc Minh Dang</a>. I also hold a B.E. degree in Electronics and Telecommunication from TDTU, which I obtained in 2019 under the supervision of Associate Professor <a href="https://dnmduc.github.io/" rel="external nofollow noopener" target="_blank">Duc Ngoc Minh Dang</a>.</p> <p><strong>Research Interests:</strong> Artificial Intelligence, Computational Intelligence, Deep Learning, Machine Learning, Signal Processing, XAI &amp; Optimization, and their applications in the fields of Affective Computing, AI4Science, Audio &amp; Speech Processing, Bioinformatics, Biomedical Data Science, Environmental Microbiology, Epigenetic Modifications, Intelligent &amp; Optimal Control, Medical Image Analysis, Multimodal Analysis, Multi-Omics Analysis, Neurodegenerative Diseases, Peptide-based Therapeutics, Protein Function and Structure Prediction, Protein Post-Translational Modifications, RNA Post-Transcriptional Modifications, RNA Secondary Structure Prediction, RNA-based Therapeutics, and Small Molecules &amp; Drug Discovery.</p> <style>.no-margin{margin:0}.custom-figure{margin-top:0}.small-figure{width:100%}.reduce-gap{margin-bottom:5}</style> <hr> <hr> <figure class="custom-figure reduce-gap"> <img src="/assets/img/laboratory.gif" class="small-figure"> </figure> <hr> <hr> <p><strong>Inspirational Quotes:</strong></p> <blockquote class="no-margin reduce-gap"> <p><q><i>I Must Betray You</i> - <i><b>Trust no one. Tell no one. Spies are everywhere.</b></i></q> - <a href="https://rutasepetys.com/books/i-must-betray-you/" rel="external nofollow noopener" target="_blank">Ruta Sepetys (R≈´ta ≈†epetys)</a></p> <p><q><i>Your origin does not determine what kind of person you are. Only you can decide who you become.</i></q> - <a href="https://mengchih.com/about/" rel="external nofollow noopener" target="_blank">Meng Chih Chiang</a></p> <p><q><i>Life can be heavy, especially if you try to carry it all at once.</i></q> - <a href="https://www.taylorswift.com/" rel="external nofollow noopener" target="_blank">Taylor Swift</a></p> <p><q><i>Life is a balance of positive and negative aspects. Therefore, it is essential to cherish every moment and embrace it fully.</i></q> - <a href="https://nhattruongpham.github.io/">Nhat Truong Pham</a></p> </blockquote> <center> $$ \begin{align*} \text{Life} &amp;= \int_{\text{birth}}^{\infty} \left(\frac{\text{Happiness} \times \text{Love} \times \text{Peace}}{\text{time}} - \frac{\text{Sadness} \times \text{Revenge} \times \text{Discord}}{\text{time}}\right) \, \text{dtime} \\ &amp;= \int_{\text{birth}}^{\rm{t_{2025}}} \left(\frac{\text{Happiness} \times \text{Love} \times \text{Peace}}{\text{time}} - \frac{\text{Sadness} \times \text{Revenge} \times \text{Discord}}{\text{time}}\right) \, \text{dtime} \\ &amp;\quad + \int_{\rm{t_{2025}}}^{\infty} \left(\frac{\text{Happiness}' \times \text{Love}' \times \text{Peace}'}{\text{time}} - \frac{\text{Sadness}' \times \text{Revenge}' \times \text{Discord}'}{\text{time}}\right) \, \text{dtime} \end{align*} $$ </center> <hr> <hr> </div> <h2> <a href="/news/" style="color: inherit">Latest News</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Nov 20, 2025</th> <td> One co-authored manuscript, entitled <b>‚Äú<i>Mulaqua:</i> An interpretable multimodal deep learning framework for identifying PMT/vPvM substances in drinking water‚Äù</b>, has been accepted for publication in the <span style="color: #FF3636;"><i>Journal of Hazardous Materials</i></span> </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 31, 2025</th> <td> One collaborative manuscript, entitled <b>‚ÄúFederated Semi-Supervised FixMatch: Enhancing CutMix for Medical Image Segmentation‚Äù</b>, has been accepted for publication in the <span style="color: #00ab37;"><i>2025 IEEE International Conference on Big Data (IEEE BigData)</i></span> </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 24, 2025</th> <td> Our project, entitled <b>‚ÄúMultiple prediction of RNA modification sites using RNA foundation models and transformer fusion (RNA ÌååÏö¥Îç∞Ïù¥ÏÖò Î™®Îç∏Îì§Í≥º Ìä∏ÎûúÏä§Ìè¨Î®∏ ÏúµÌï©ÏùÑ ÌôúÏö©Ìïú RNA Î≥ÄÌòï Î∂ÄÏúÑ Îã§Ï§ë ÏòàÏ∏°)‚Äù</b>, has been selected for the <span style="color: #F29105;"><i>2025 3rd K-BDS analysis infrastructure utilization support program ([Track I] Large innovation research)</i></span> by the <a href="https://kbdsc.kisti.re.kr/index" rel="external nofollow noopener" target="_blank">Korea Bio Data Station (K-BDS)</a>, <a href="https://www.kisti.re.kr/eng/" rel="external nofollow noopener" target="_blank">Korea Institute of Science and Technology Information</a>, Republic of Korea </td> </tr> </table> </div> </div> <hr> <hr> <h2> <a href="/publications/" style="color: inherit">Selected Publications</a> </h2> <div class="publications"> <p> (‚Ä†) denotes equal contribution </p> <p> (*) denotes correspondance </p> <p> <span style="display: inline-block; width: 15px; height: 15px; background-color: #600;"></span> denotes journal </p> <p> <span style="display: inline-block; width: 15px; height: 15px; background-color: #215d42;"></span> denotes conference </p> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#600"> <a href="https://jcheminf.biomedcentral.com/" rel="external nofollow noopener" target="_blank">JCheminf</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/xBitterT5.jpg" sizes="200px"> <img src="/assets/img/publication_preview/xBitterT5.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="xBitterT5.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="khater2025generative" class="col-sm-8"> <div class="title"> <b><i>xBitterT5:</i></b> an explainable transformer-based framework with multimodal inputs for identifying bitter-taste peptides</div> <div class="author"> <a href="https://scholar.google.com/citations?hl=en&amp;user=-aEoZCgAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Nguyen Doan Hieu Nguyen<sup>‚Ä†</sup></a> ,¬†<em><b style="color: #FFA500;">Nhat Truong Pham<sup>‚Ä†</sup></b></em> ,¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=kz_chQ4AAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Duong Thanh Tran</a> ,¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=0EAV03MAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Leyi Wei</a> ,¬†Adeel Malik ,¬†and¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=0vkenbwAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Balachandran Manavalan</a> </div> <div class="periodical"> <em><i><a href="https://jcheminf.biomedcentral.com/" style="color: #FF3636; text-decoration: underline dashed;" rel="external nofollow noopener" target="_blank">Journal of Cheminformatics</a></i></em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://jcheminf.biomedcentral.com/articles/10.1186/s13321-025-01078-1" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/xBitterT5.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> <a href="https://github.com/cbbl-skku-org/xBitterT5/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://balalab-skku.org/xBitterT5/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>Bitter peptides (BPs), derived from the hydrolysis of proteins in food, play a crucial role in both food science and biomedicine by influencing taste perception and participating in various physiological processes. Accurate identification of BPs is essential for understanding food quality and potential health impacts. Traditional machine learning approaches for BP identification have relied on conventional feature descriptors, achieving moderate success but struggling with the complexities of biological sequence data. Recent advances utilizing protein language model embedding and meta-learning approaches have improved the accuracy, but frequently neglect the molecular representations of peptides and lack interpretability. In this study, we propose xBitterT5, a novel multimodal and interpretable framework for BP identification that integrates pretrained transformer-based embeddings from BioT5+ with the combination of peptide sequence and its SELFIES molecular representation. Specifically, incorporating both peptide sequences and their molecular strings, xBitterT5 demonstrates superior performance compared to previous methods on the same benchmark datasets. Importantly, the model provides residue-level interpretability, highlighting chemically meaningful substructures that significantly contribute to its bitterness, thus offering mechanistic insights beyond black-box predictions. A user-friendly web server (<a href="https://balalab-skku.org/xBitterT5/" rel="external nofollow noopener" target="_blank">https://balalab-skku.org/xBitterT5/</a>) and a standalone version (<a href="https://github.com/cbbl-skku-org/xBitterT5/" rel="external nofollow noopener" target="_blank">https://github.com/cbbl-skku-org/xBitterT5/</a>) are freely available to support both computational biologists and experimental researchers in peptide-based food and biomedicine. </p> <p><b>Scientific Contribution</b></p> <p>We propose xBitterT5, a novel multimodal transformer-based framework for the identification of BPs. By utilizing the pretrained BioT5+ model, xBitterT5 effectively extracts high-level representations from both the peptide sequences and their corresponding SELFIES molecular representation. This dual-modality approach enables a more comprehensive understanding of the peptide sequence by leveraging its molecular string, leading to substantial improvements in performance across two benchmark datasets. Additionally, xBitterT5 offers interpretability by identifying key molecular substructures that contribute to bitterness, thereby providing mechanistic insights essential for peptide-based food and drug applications.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">khater2025generative</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{xBitterT5: an explainable transformer-based framework with multimodal inputs for identifying bitter-taste peptides}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nguyen, Nguyen Doan Hieu and Pham, Nhat Truong and Tran, Duong Thanh and Wei, Leyi and Malik, Adeel and Manavalan, Balachandran}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Cheminformatics}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{17}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{127}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1186/s13321-025-01078-1}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#600"> <a href="https://www.sciencedirect.com/journal/journal-of-pharmaceutical-analysis" rel="external nofollow noopener" target="_blank">JPA</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/HyPepTox-Fuse.jpg" sizes="200px"> <img src="/assets/img/publication_preview/HyPepTox-Fuse.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="HyPepTox-Fuse.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="tran2025hypeptox" class="col-sm-8"> <div class="title"> <b><i>HyPepTox-Fuse:</i></b> An interpretable hybrid framework for accurate peptide toxicity prediction fusing protein language model-based embeddings with conventional descriptors</div> <div class="author"> <a href="https://scholar.google.com/citations?hl=en&amp;user=kz_chQ4AAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Duong Thanh Tran<sup>‚Ä†</sup></a> ,¬†<em><b style="color: #FFA500;">Nhat Truong Pham<sup>‚Ä†</sup></b></em> ,¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=-aEoZCgAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Nguyen Doan Hieu Nguyen</a> ,¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=0EAV03MAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Leyi Wei</a> ,¬†and¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=0vkenbwAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Balachandran Manavalan</a> </div> <div class="periodical"> <em><i><a href="https://www.sciencedirect.com/journal/journal-of-pharmaceutical-analysis" style="color: #FF3636; text-decoration: underline dashed;" rel="external nofollow noopener" target="_blank">Journal of Pharmaceutical Analysis</a></i></em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/pii/S2095177925002278" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/HyPepTox-Fuse.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> <a href="https://github.com/cbbl-skku-org/HyPepTox-Fuse/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://balalab-skku.org/HyPepTox-Fuse/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>Peptide-based therapeutics hold great promise for the treatment of various diseases; however, their clinical application is often hindered by toxicity challenges. The accurate prediction of peptide toxicity is crucial for designing safe peptide-based therapeutics. While traditional experimental approaches are time-consuming and expensive, computational methods have emerged as viable alternatives, including similarity-based and machine learning (ML)-/deep learning (DL)-based methods. However, existing methods often struggle with robustness and generalizability. To address these challenges, we propose HyPepTox-Fuse, a novel framework that fuses protein language model (PLM)-based embeddings with conventional descriptors. HyPepTox-Fuse integrates ensemble PLM-based embeddings to achieve richer peptide representations by leveraging a cross-modal multi-head attention mechanism and Transformer architecture. A robust feature ranking and selection pipeline further refines conventional descriptors, thus enhancing prediction performance. Our framework outperforms state-of-the-art methods in cross-validation and independent evaluations, offering a scalable and reliable tool for peptide toxicity prediction. Moreover, we conducted a case study to validate the robustness and generalizability of HyPepTox-Fuse, highlighting its effectiveness in enhancing model performance. Furthermore, the HyPepTox-Fuse server is freely accessible at https://balalab-skku.org/HyPepTox-Fuse/ and the source code is publicly available at <a href="https://github.com/cbbl-skku-org/HyPepTox-Fuse/" rel="external nofollow noopener" target="_blank">https://github.com/cbbl-skku-org/HyPepTox-Fuse/</a>. The study thus presents an intuitive platform for predicting peptide toxicity and supports reproducibility through openly available datasets.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">tran2025hypeptox</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{HyPepTox-Fuse: An interpretable hybrid framework for accurate peptide toxicity prediction fusing protein language model-based embeddings with conventional descriptors}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tran, Duong Thanh and Pham, Nhat Truong and Nguyen, Nguyen Doan Hieu and Wei, Leyi and Manavalan, Balachandran}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Pharmaceutical Analysis}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{15}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{101410}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.jpha.2025.101410}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#600"> <a href="https://www.sciencedirect.com/journal/journal-of-molecular-biology" rel="external nofollow noopener" target="_blank">JMB</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/DOGpred.jpeg" sizes="200px"> <img src="/assets/img/publication_preview/DOGpred.jpeg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="DOGpred.jpeg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="lee2025dogpred" class="col-sm-8"> <div class="title"> <b><i>DOGpred:</i></b> A Novel Deep Learning Framework for Accurate Identification of Human O-linked Threonine Glycosylation Sites</div> <div class="author"> Ki Wook Lee<sup>‚Ä†</sup> ,¬†<em><b style="color: #FFA500;">Nhat Truong Pham<sup>‚Ä†</sup></b></em> ,¬†Hye Jung Min ,¬†Hyun Woo Park ,¬†Ji Won Lee ,¬†Han-En Lo ,¬†Na Young Kwon ,¬†Jimin Seo ,¬†Illia Shaginyan ,¬†Heeje Cho ,¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=0EAV03MAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Leyi Wei</a> ,¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=0vkenbwAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Balachandran Manavalan</a> ,¬†and¬†Young-Jun Jeon </div> <div class="periodical"> <em><i><a href="https://www.sciencedirect.com/journal/journal-of-molecular-biology" style="color: #FF3636; text-decoration: underline dashed;" rel="external nofollow noopener" target="_blank">Journal of Molecular Biology</a></i></em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/pii/S0022283625000439" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/JeonRPM/DOGpred/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://doi.org/10.5281/zenodo.13141341" rel="external nofollow noopener" target="_blank"> <img src="https://zenodo.org/badge/doi/10.5281/zenodo.13141341.svg" alt="DOI"> </a> </div> <div class="abstract hidden"> <p>O-linked glycosylation is a crucial post-transcriptional modification that regulates protein function and biological processes. Dysregulation of this process is associated with various diseases, underscoring the need to accurately identify O-linked glycosylation sites on proteins. Current experimental methods for identifying O-linked threonine glycosylation (OTG) sites are often complex and costly. Consequently, developing computational tools that predict these sites based on protein features is crucial. Such tools can complement experimental approaches, enhancing our understanding of the role of OTG dysregulation in diseases and uncovering potential therapeutic targets. In this study, we developed DOGpred, a deep learning-based predictor for precisely identifying human OTGs using high-latent feature representations. Initially, we extracted nine different conventional feature descriptors (CFDs) and nine pre-trained protein language model (PLM)-based embeddings. Notably, each feature was encoded as a 2D tensor, capturing both the sequential and inherent feature characteristics. Subsequently, we designed a stacked convolutional neural network (CNN) module to learn spatial feature representations from CFDs and a stacked recurrent neural network (RNN) module to learn temporal feature representations from PLM-based embeddings. These features were integrated using attention-based fusion mechanisms to generate high-level feature representations for final classification. Ablation analysis and independent tests demonstrated that the optimal model (DOGpred), employing a stacked 1D CNN and a stacked attention-based RNN module with cross-attention feature fusion, achieved the best performance on the training dataset and significantly outperformed machine learning-based single-feature models and state-of-the-art methods on independent datasets. Furthermore, DOGpred is publicly available at <a href="https://github.com/JeonRPM/DOGpred/" rel="external nofollow noopener" target="_blank">https://github.com/JeonRPM/DOGpred/</a> for free access and usage.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">lee2025dogpred</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{DOGpred: A Novel Deep Learning Framework for Accurate Identification of Human O-linked Threonine Glycosylation Sites}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lee, Ki Wook and Pham, Nhat Truong and Min, Hye Jung and Park, Hyun Woo and Lee, Ji Won and Lo, Han-En and Kwon, Na Young and Seo, Jimin and Shaginyan, Illia and Cho, Heeje and Wei, Leyi and Manavalan, Balachandran and Jeon, Young-Jun}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Molecular Biology}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{437}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{168977}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.jmb.2025.168977}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#215d42"> <a href="https://language-plus-molecules.github.io/" rel="external nofollow noopener" target="_blank">LPM@ACL</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Mol2Lang-VLM.png" sizes="200px"> <img src="/assets/img/publication_preview/Mol2Lang-VLM.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Mol2Lang-VLM.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="tran2024mollangvlm" class="col-sm-8"> <div class="title"> <b><i>Mol2Lang-VLM:</i></b> Vision- and Text-Guided Generative Pre-trained Language Models for Advancing Molecule Captioning through Multimodal Fusion</div> <div class="author"> <a href="https://scholar.google.com/citations?hl=en&amp;user=kz_chQ4AAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Duong Thanh Tran<sup>‚Ä†</sup></a> ,¬†<em><b style="color: #FFA500;">Nhat Truong Pham<sup>‚Ä†</sup></b></em> ,¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=-aEoZCgAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Nguyen Doan Hieu Nguyen</a> ,¬†and¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=0vkenbwAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Balachandran Manavalan</a> </div> <div class="periodical"> <em>In <i><a href="https://language-plus-molecules.github.io/" style="color: #00ab37; text-decoration: underline dashed;" rel="external nofollow noopener" target="_blank">Proceedings of the 1st Workshop on Language + Molecules (L+M 2024)</a></i></em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://aclanthology.org/2024.langmol-1.12/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://aclanthology.org/2024.langmol-1.12.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/nhattruongpham/mol-lang-bridge/tree/mol2lang" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>This paper introduces Mol2Lang-VLM, an enhanced method for refining generative pre-trained language models for molecule captioning using multimodal features to achieve more accurate caption generation. Our approach leverages the encoder and decoder blocks of the Transformer-based architecture by introducing third sub-layers into both. Specifically, we insert sub-layers in the encoder to fuse features from SELFIES strings and molecular images, while the decoder fuses features from SMILES strings and their corresponding descriptions. Moreover, cross multi-head attention is employed instead of common multi-head attention to enable the decoder to attend to the encoder‚Äôs output, thereby integrating the encoded contextual information for better and more accurate caption generation. Performance evaluation on the CheBI-20 and L+M-24 benchmark datasets demonstrates Mol2Lang-VLM‚Äôs superiority, achieving higher accuracy and quality in caption generation compared to existing methods. Our code and pre-processed data are available at <a href="https://github.com/nhattruongpham/mol-lang-bridge/tree/mol2lang" rel="external nofollow noopener" target="_blank">https://github.com/nhattruongpham/mol-lang-bridge/tree/mol2lang/</a>.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">tran2024mollangvlm</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Mol2Lang-{VLM}: Vision- and Text-Guided Generative Pre-trained Language Models for Advancing Molecule Captioning through Multimodal Fusion}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tran, Duong Thanh and Pham, Nhat Truong and Nguyen, Nguyen Doan Hieu and Manavalan, Balachandran}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 1st Workshop on Language + Molecules L+M 2024}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{97--102}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.18653/v1/2024.langmol-1.12}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#215d42"> <a href="https://language-plus-molecules.github.io/" rel="external nofollow noopener" target="_blank">LPM@ACL</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Lang2Mol-Diff.png" sizes="200px"> <img src="/assets/img/publication_preview/Lang2Mol-Diff.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Lang2Mol-Diff.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="nguyen2024langmoldiff" class="col-sm-8"> <div class="title"> <b><i>Lang2Mol-Diff:</i></b> A Diffusion-Based Generative Model for Language-to-Molecule Translation Leveraging SELFIES Molecular String Representation</div> <div class="author"> <a href="https://scholar.google.com/citations?hl=en&amp;user=-aEoZCgAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Nguyen Doan Hieu Nguyen<sup>‚Ä†</sup></a> ,¬†<em><b style="color: #FFA500;">Nhat Truong Pham<sup>‚Ä†</sup></b></em> ,¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=kz_chQ4AAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Duong Thanh Tran</a> ,¬†and¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=0vkenbwAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Balachandran Manavalan</a> </div> <div class="periodical"> <em>In <i><a href="https://language-plus-molecules.github.io/" style="color: #00ab37; text-decoration: underline dashed;" rel="external nofollow noopener" target="_blank">Proceedings of the 1st Workshop on Language + Molecules (L+M 2024)</a></i></em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://aclanthology.org/2024.langmol-1.15/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://aclanthology.org/2024.langmol-1.15.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/nhattruongpham/mol-lang-bridge/tree/lang2mol" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Generating <i>de novo</i> molecules from textual descriptions is challenging due to potential issues with molecule validity in SMILES representation and limitations of autoregressive models. This work introduces Lang2Mol-Diff, a diffusion-based language-to-molecule generative model using the SELFIES representation. Specifically, Lang2Mol-Diff leverages the strengths of two state-of-the-art molecular generative models: BioT5 and TGM-DLM. By employing BioT5 to tokenize the SELFIES representation, Lang2Mol-Diff addresses the validity issues associated with SMILES strings. Additionally, it incorporates a text diffusion mechanism from TGM-DLM to overcome the limitations of autoregressive models in this domain. To the best of our knowledge, this is the first study to leverage the diffusion mechanism for text-based <i>de novo</i> molecule generation using the SELFIES molecular string representation. Performance evaluation on the L+M-24 benchmark dataset shows that Lang2Mol-Diff outperforms all existing methods for molecule generation in terms of validity. Our code and pre-processed data are available at <a href="https://github.com/nhattruongpham/mol-lang-bridge/tree/lang2mol" rel="external nofollow noopener" target="_blank">https://github.com/nhattruongpham/mol-lang-bridge/tree/lang2mol/</a>.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">nguyen2024langmoldiff</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Lang2Mol-Diff: A Diffusion-Based Generative Model for Language-to-Molecule Translation Leveraging SELFIES Molecular String Representation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nguyen, Nguyen Doan Hieu and Pham, Nhat Truong and Tran, Duong Thanh and Manavalan, Balachandran}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 1st Workshop on Language + Molecules L+M 2024}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{128--134}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.18653/v1/2024.langmol-1.15}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#600"> <a href="https://www.sciencedirect.com/journal/computers-in-biology-and-medicine" rel="external nofollow noopener" target="_blank">CIBM</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/HOTGpred.png" sizes="200px"> <img src="/assets/img/publication_preview/HOTGpred.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="HOTGpred.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="pham2024hotgpred" class="col-sm-8"> <div class="title"> <b><i>HOTGpred:</i></b> Enhancing human O-linked threonine glycosylation prediction using integrated pretrained protein language model-based features and multi-stage feature selection approach</div> <div class="author"> <em><b style="color: #FFA500;">Nhat Truong Pham<sup>‚Ä†</sup></b></em> ,¬†Ying Zhang<sup>‚Ä†</sup> ,¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=5WP7pOUAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Rajan Rakkiyappan</a> ,¬†and¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=0vkenbwAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Balachandran Manavalan</a> </div> <div class="periodical"> <em><i><a href="https://www.sciencedirect.com/journal/computers-in-biology-and-medicine" style="color: #FF3636; text-decoration: underline dashed;" rel="external nofollow noopener" target="_blank">Computers in Biology and Medicine</a></i></em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/abs/pii/S0010482524009442" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://balalab-skku.org/HOTGpred/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>O-linked glycosylation is a complex post-translational modification (PTM) in human proteins that plays a critical role in regulating various cellular metabolic and signaling pathways. In contrast to N-linked glycosylation, O-linked glycosylation lacks specific sequence features and maintains an unstable core structure. Identifying O-linked threonine glycosylation sites (OTGs) remains challenging, requiring extensive experimental tests. While bioinformatics tools have emerged for predicting OTGs, their reliance on limited conventional features and absence of well-defined feature selection strategies limit their effectiveness. To address these limitations, we introduced HOTGpred (Human O-linked Threonine Glycosylation predictor), employing a multi-stage feature selection process to identify the optimal feature set for accurately identifying OTGs. Initially, we assessed 25 different feature sets derived from various pretrained protein language model (PLM)-based embeddings and conventional feature descriptors using nine classifiers. Subsequently, we integrated the top five embeddings linearly and determined the most effective scoring function for ranking hybrid features, identifying the optimal feature set through a process of sequential forward search. Among the classifiers, the extreme gradient boosting (XGBT)-based model, using the optimal feature set (HOTGpred), achieved 92.03% accuracy on the training dataset and 88.25% on the balanced independent dataset. Notably, HOTGpred significantly outperformed the current state-of-the-art methods on both the balanced and imbalanced independent datasets, demonstrating its superior prediction capabilities. Additionally, SHapley Additive exPlanations (SHAP) and ablation analyses were conducted to identify the features contributing most significantly to HOTGpred. Finally, we developed an easy-to-navigate web server, accessible at <a href="https://balalab-skku.org/HOTGpred/" rel="external nofollow noopener" target="_blank">https://balalab-skku.org/HOTGpred/</a>, to support glycobiologists in their research on glycosylation structure and function.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">pham2024hotgpred</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{HOTGpred: Enhancing human O-linked threonine glycosylation prediction using integrated pretrained protein language model-based features and multi-stage feature selection approach}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pham, Nhat Truong and Zhang, Ying and Rakkiyappan, Rajan and Manavalan, Balachandran}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Computers in Biology and Medicine}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{179}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{108859}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.compbiomed.2024.108859}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#600"> <a href="https://www.sciencedirect.com/journal/journal-of-molecular-biology" rel="external nofollow noopener" target="_blank">JMB</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/mACPpred2.png" sizes="200px"> <img src="/assets/img/publication_preview/mACPpred2.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="mACPpred2.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="sangaraju2024macppred" class="col-sm-8"> <div class="title"> <b><i>mACPpred 2.0:</i></b> Stacked Deep Learning for Anticancer Peptide Prediction with Integrated Spatial and Probabilistic Feature Representations</div> <div class="author"> Vinoth Kumar Sangaraju<sup>‚Ä†</sup> ,¬†<em><b style="color: #FFA500;">Nhat Truong Pham<sup>‚Ä†</sup></b></em> ,¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=0EAV03MAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Leyi Wei</a> ,¬†Xue Yu ,¬†and¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=0vkenbwAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Balachandran Manavalan</a> </div> <div class="periodical"> <em><i><a href="https://www.sciencedirect.com/journal/journal-of-molecular-biology" style="color: #FF3636; text-decoration: underline dashed;" rel="external nofollow noopener" target="_blank">Journal of Molecular Biology</a></i></em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/abs/pii/S0022283624002894" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/nhattruongpham/mACPpred2/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://balalab-skku.org/mACPpred2/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> <a href="https://doi.org/10.5281/zenodo.11350064" rel="external nofollow noopener" target="_blank"> <img src="https://zenodo.org/badge/doi/10.5281/zenodo.11350064.svg" alt="DOI"> </a> </div> <div class="abstract hidden"> <p>Anticancer peptides (ACPs), naturally occurring molecules with remarkable potential to target and kill cancer cells. However, identifying ACPs based solely from their primary amino acid sequences remains a major hurdle in immunoinformatics. In the past, several web-based machine learning (ML) tools have been proposed to assist researchers in identifying potential ACPs for further testing. Notably, our meta-approach method, mACPpred, introduced in 2019, has significantly advanced the field of ACP research. Given the exponential growth in the number of characterized ACPs, there is now a pressing need to create an updated version of mACPpred. To develop mACPpred 2.0, we constructed an up-to-date benchmarking dataset by integrating all publicly available ACP datasets. We employed a large-scale of feature descriptors, encompassing both conventional feature descriptors and advanced pre-trained natural language processing (NLP)-based embeddings. We evaluated their ability to discriminate between ACPs and non-ACPs using eleven different classifiers. Subsequently, we employed a stacked deep learning (SDL) approach, incorporating 1D convolutional neural network (1D CNN) blocks and hybrid features. These features included the top seven performing NLP-based features and 90 probabilistic features, allowing us to identify hidden patterns within these diverse features and improve the accuracy of our ACP prediction model. This is the first study to integrate spatial and probabilistic feature representations for predicting ACPs. Rigorous cross-validation and independent tests conclusively demonstrated that mACPpred 2.0 not only surpassed its predecessor (mACPpred) but also outperformed the existing state-of-the-art predictors, highlighting the importance of advanced feature representation capabilities attained through SDL. To facilitate widespread use and accessibility, we have developed a user-friendly for mACPpred 2.0, available at <a href="https://balalab-skku.org/mACPpred2/" rel="external nofollow noopener" target="_blank">https://balalab-skku.org/mACPpred2/</a>.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">sangaraju2024macppred</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{mACPpred 2.0: Stacked Deep Learning for Anticancer Peptide Prediction with Integrated Spatial and Probabilistic Feature Representations}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sangaraju, Vinoth Kumar and Pham, Nhat Truong and Wei, Leyi and Yu, Xue and Manavalan, Balachandran}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Molecular Biology}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{436}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{17}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{168687}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.jmb.2024.168687}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#600"> <a href="https://www.cell.com/molecular-therapy-family/nucleic-acids/home" rel="external nofollow noopener" target="_blank">MTNA</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/ac4C-AFL.png" sizes="200px"> <img src="/assets/img/publication_preview/ac4C-AFL.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ac4C-AFL.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="pham2024ac4c" class="col-sm-8"> <div class="title"> <b><i>ac4C-AFL:</i></b> A high-precision identification of human mRNA N4-acetylcytidine sites based on adaptive feature representation learning</div> <div class="author"> <em><b style="color: #FFA500;">Nhat Truong Pham</b></em> ,¬†Annie Terrina Terrance ,¬†Young-Jun Jeon ,¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=5WP7pOUAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Rajan Rakkiyappan</a> ,¬†and¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=0vkenbwAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Balachandran Manavalan</a> </div> <div class="periodical"> <em><i><a href="https://www.cell.com/molecular-therapy-family/nucleic-acids/home" style="color: #FF3636; text-decoration: underline dashed;" rel="external nofollow noopener" target="_blank">Molecular Therapy-Nucleic Acids</a></i></em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.cell.com/molecular-therapy-family/nucleic-acids/fulltext/S2162-2531(24)00079-9" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/ac4C-AFL.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> <a href="https://balalab-skku.org/ac4C-AFL/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>RNA N4-acetylcytidine (ac4C) is a highly conserved RNA modification that plays a crucial role in controlling mRNA stability, processing, and translation. Consequently, accurate identification of ac4C sites across the genome is critical for understanding gene expression regulation mechanisms. In this study, we have developed ac4C-AFL, a bioinformatics tool that precisely identifies ac4C sites from primary RNA sequences. In ac4C-AFL, we identified the optimal sequence length for model building and implemented an adaptive feature representation strategy that is capable of extracting the most representative features from RNA. To identify the most relevant features, we proposed a novel ensemble feature importance scoring strategy to rank features effectively. We then used this information to conduct the sequential forward search, which individually determine the optimal feature set from the 16 sequence-derived feature descriptors. Utilizing these optimal feature descriptors, we constructed 176 baseline models using 11 popular classifiers. The most efficient baseline models were identified using the two-step feature selection approach, whose predicted scores were integrated and trained with the appropriate classifier to develop the final prediction model. Our rigorous cross-validations and independent tests demonstrate that ac4C-AFL surpasses contemporary tools in predicting ac4C sites. Moreover, we have developed a publicly accessible web server at <a href="https://balalab-skku.org/ac4C-AFL/" rel="external nofollow noopener" target="_blank">https://balalab-skku.org/ac4C-AFL/</a>.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">pham2024ac4c</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{ac4C-AFL: A high-precision identification of human mRNA N4-acetylcytidine sites based on adaptive feature representation learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pham, Nhat Truong and Terrance, Annie Terrina and Jeon, Young-Jun and Rakkiyappan, Rajan and Manavalan, Balachandran}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Molecular Therapy-Nucleic Acids}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{35}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{102192}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.omtn.2024.102192}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#600"> <a href="https://academic.oup.com/bib" rel="external nofollow noopener" target="_blank">BiB</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/H2Opred.png" sizes="200px"> <img src="/assets/img/publication_preview/H2Opred.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="H2Opred.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="pham2024h2opred" class="col-sm-8"> <div class="title"> <b><i>H2Opred:</i></b> a robust and efficient hybrid deep learning model for predicting 2‚Äô-O-methylation sites in human RNA</div> <div class="author"> <em><b style="color: #FFA500;">Nhat Truong Pham</b></em> ,¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=5WP7pOUAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Rajan Rakkiyappan</a> ,¬†Jongsun Park ,¬†Adeel Malik ,¬†and¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=0vkenbwAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Balachandran Manavalan</a> </div> <div class="periodical"> <em><i><a href="https://academic.oup.com/bib" style="color: #FF3636; text-decoration: underline dashed;" rel="external nofollow noopener" target="_blank">Briefings in Bioinformatics</a></i></em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://academic.oup.com/bib/article/25/1/bbad476/7510980" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/H2Opred.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> <a href="https://balalab-skku.org/H2Opred/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> <a href="https://www.ibric.org/s.do?CWXEPvOoln" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Media</a> </div> <div class="abstract hidden"> <p>2‚Äô-O-methylation (2OM) is the most common post-transcriptional modification of RNA. It plays a crucial role in RNA splicing, RNA stability and innate immunity. Despite advances in high-throughput detection, the chemical stability of 2OM makes it difficult to detect and map in messenger RNA. Therefore, bioinformatics tools have been developed using machine learning (ML) algorithms to identify 2OM sites. These tools have made significant progress, but their performances remain unsatisfactory and need further improvement. In this study, we introduced H2Opred, a novel hybrid deep learning (HDL) model for accurately identifying 2OM sites in human RNA. Notably, this is the first application of HDL in developing four nucleotide-specific models [adenine (A2OM), cytosine (C2OM), guanine (G2OM) and uracil (U2OM)] as well as a generic model (N2OM). H2Opred incorporated both stacked 1D convolutional neural network (1D-CNN) blocks and stacked attention-based bidirectional gated recurrent unit (Bi-GRU-Att) blocks. 1D-CNN blocks learned effective feature representations from 14 conventional descriptors, while Bi-GRU-Att blocks learned feature representations from five natural language processing-based embeddings extracted from RNA sequences. H2Opred integrated these feature representations to make the final prediction. Rigorous cross-validation analysis demonstrated that H2Opred consistently outperforms conventional ML-based single-feature models on five different datasets. Moreover, the generic model of H2Opred demonstrated a remarkable performance on both training and testing datasets, significantly outperforming the existing predictor and other four nucleotide-specific H2Opred models. To enhance accessibility and usability, we have deployed a user-friendly web server for H2Opred, accessible at <a href="https://balalab-skku.org/H2Opred/" rel="external nofollow noopener" target="_blank">https://balalab-skku.org/H2Opred/</a>. This platform will serve as an invaluable tool for accurately predicting 2OM sites within human RNA, thereby facilitating broader applications in relevant research endeavors.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">pham2024h2opred</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{H2Opred: a robust and efficient hybrid deep learning model for predicting 2'-O-methylation sites in human RNA}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pham, Nhat Truong and Rakkiyappan, Rajan and Park, Jongsun and Malik, Adeel and Manavalan, Balachandran}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Briefings in Bioinformatics}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{25}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{bbad476}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{OxfOxford University Pressord}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1093/bib/bbad476}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#600"> <a href="https://academic.oup.com/bib" rel="external nofollow noopener" target="_blank">BiB</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/MeL-STPhos.png" sizes="200px"> <img src="/assets/img/publication_preview/MeL-STPhos.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="MeL-STPhos.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="pham2024advancing" class="col-sm-8"> <div class="title">Advancing the accuracy of SARS-CoV-2 phosphorylation site detection via meta-learning approach</div> <div class="author"> <em><b style="color: #FFA500;">Nhat Truong Pham<sup>‚Ä†</sup></b></em> ,¬†Le Thi Phan<sup>‚Ä†</sup> ,¬†Jimin Seo ,¬†Yeonwoo Kim ,¬†Minkyung Song ,¬†Sukchan Lee ,¬†Young-Jun Jeon ,¬†and¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=0vkenbwAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Balachandran Manavalan</a> </div> <div class="periodical"> <em><i><a href="https://academic.oup.com/bib" style="color: #FF3636; text-decoration: underline dashed;" rel="external nofollow noopener" target="_blank">Briefings in Bioinformatics</a></i></em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://academic.oup.com/bib/article/25/1/bbad433/7459584" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/MeL-STPhos.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> <a href="https://balalab-skku.org/MeL-STPhos/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> <a href="https://www.ibric.org/s.do?nLdsctWFBW" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Media</a> <a href="https://www.ibric.org/s.do?ovlRZSpKQk" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Interview</a> </div> <div class="abstract hidden"> <p>The worldwide appearance of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has generated significant concern and posed a considerable challenge to global health. Phosphorylation is a common post-translational modification that affects many vital cellular functions and is closely associated with SARS-CoV-2 infection. Precise identification of phosphorylation sites could provide more in-depth insight into the processes underlying SARS-CoV-2 infection and help alleviate the continuing coronavirus disease 2019 (COVID-19) crisis. Currently, available computational tools for predicting these sites lack accuracy and effectiveness. In this study, we designed an innovative meta-learning model, Meta-Learning for Serine/Threonine Phosphorylation (MeL-STPhos), to precisely identify protein phosphorylation sites. We initially performed a comprehensive assessment of 29 unique sequence-derived features, establishing prediction models for each using 14 renowned machine learning methods, ranging from traditional classifiers to advanced deep learning algorithms. We then selected the most effective model for each feature by integrating the predicted values. Rigorous feature selection strategies were employed to identify the optimal base models and classifier(s) for each cell-specific dataset. To the best of our knowledge, this is the first study to report two cell-specific models and a generic model for phosphorylation site prediction by utilizing an extensive range of sequence-derived features and machine learning algorithms. Extensive cross-validation and independent testing revealed that MeL-STPhos surpasses existing state-of-the-art tools for phosphorylation site prediction. We also developed a publicly accessible platform at <a href="https://balalab-skku.org/MeL-STPhos/" rel="external nofollow noopener" target="_blank">https://balalab-skku.org/MeL-STPhos/</a>. We believe that MeL-STPhos will serve as a valuable tool for accelerating the discovery of serine/threonine phosphorylation sites and elucidating their role in post-translational regulation.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">pham2024advancing</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Advancing the accuracy of SARS-CoV-2 phosphorylation site detection via meta-learning approach}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pham, Nhat Truong and Phan, Le Thi and Seo, Jimin and Kim, Yeonwoo and Song, Minkyung and Lee, Sukchan and Jeon, Young-Jun and Manavalan, Balachandran}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Briefings in Bioinformatics}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{25}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{bbad433}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{OxfOxford University Pressord}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1093/bib/bbad433}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#600"> <a href="https://www.sciencedirect.com/journal/expert-systems-with-applications" rel="external nofollow noopener" target="_blank">ESWA</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/HDA_mADCRNN.png" sizes="200px"> <img src="/assets/img/publication_preview/HDA_mADCRNN.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="HDA_mADCRNN.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="pham2023hybrid" class="col-sm-8"> <div class="title">Hybrid data augmentation and deep attention-based dilated convolutional-recurrent neural networks for speech emotion recognition</div> <div class="author"> <em><b style="color: #FFA500;">Nhat Truong Pham</b></em> ,¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=2UKP440AAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Duc Ngoc Minh Dang</a> ,¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=At-Y-H8AAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Ngoc Duy Nguyen</a> ,¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=xr39SOwAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Thanh Thi Nguyen</a> ,¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=5b9ncWoAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Hai Nguyen</a> ,¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=0vkenbwAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Balachandran Manavalan</a> ,¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=an_4IJkAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Chee Peng Lim</a> ,¬†and¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=XFUxOkoAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Sy Dzung Nguyen</a> </div> <div class="periodical"> <em><i><a href="https://www.sciencedirect.com/journal/expert-systems-with-applications" style="color: #FF3636; text-decoration: underline dashed;" rel="external nofollow noopener" target="_blank">Expert Systems with Applications</a></i></em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2109.09026" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/pii/S0957417423011107" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/HDA_mADCRNN.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> <a href="https://github.com/nhattruongpham/hda-adcrnn-ser" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Recently, speech emotion recognition (SER) has become an active research area in speech processing, particularly with the advent of deep learning (DL). Numerous DL-based methods have been proposed for SER. However, most of the existing DL-based models are complex and require a large amounts of data to achieve a good performance. In this study, a new framework of deep attention-based dilated convolutional-recurrent neural networks coupled with a hybrid data augmentation method was proposed for addressing SER tasks. The hybrid data augmentation method constitutes an upsampling technique for generating more speech data samples based on the traditional and generative adversarial network approaches. By leveraging both convolutional and recurrent neural networks in a dilated form along with an attention mechanism, the proposed DL framework can extract high-level representations from three-dimensional log Mel spectrogram features. Dilated convolutional neural networks acquire larger receptive fields, whereas dilated recurrent neural networks overcome complex dependencies as well as the vanishing and exploding gradient issues. Furthermore, the loss functions are reconfigured by combining the SoftMax loss and the center-based losses to classify various emotional states. The proposed framework was implemented using the Python programming language and the TensorFlow deep learning library. To validate the proposed framework, the EmoDB and ERC benchmark datasets, which are imbalanced and/or small datasets, were employed. The experimental results indicate that the proposed framework outperforms other related state-of-the-art methods, yielding the highest unweighted recall rates of 88.03 ¬± 1.39 (%) and 66.56 ¬± 0.67 (%) for the EmoDB and ERC datasets, respectively.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">pham2023hybrid</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Hybrid data augmentation and deep attention-based dilated convolutional-recurrent neural networks for speech emotion recognition}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pham, Nhat Truong and Dang, Duc Ngoc Minh and Nguyen, Ngoc Duy and Nguyen, Thanh Thi and Nguyen, Hai and Manavalan, Balachandran and Lim, Chee Peng and Nguyen, Sy Dzung}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Expert Systems with Applications}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{120608}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.eswa.2023.120608}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#600"> <a href="https://www.sciencedirect.com/journal/expert-systems-with-applications" rel="external nofollow noopener" target="_blank">ESWA</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Fruit-CoV.png" sizes="200px"> <img src="/assets/img/publication_preview/Fruit-CoV.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Fruit-CoV.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="nguyen2023fruit" class="col-sm-8"> <div class="title"> <b><i>Fruit-CoV:</i></b> An efficient vision-based framework for speedy detection and diagnosis of SARS-CoV-2 infections through recorded cough sounds</div> <div class="author"> Long H. Nguyen<sup>‚Ä†</sup> ,¬†<em><b style="color: #FFA500;">Nhat Truong Pham<sup>‚Ä†*</sup></b></em> ,¬†Van Huong Do ,¬†Liu Tai Nguyen ,¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=zSAfD80AAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Thanh Tin Nguyen</a> ,¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=5b9ncWoAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Hai Nguyen</a> ,¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=At-Y-H8AAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Ngoc Duy Nguyen</a> ,¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=xr39SOwAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Thanh Thi Nguyen</a> ,¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=XFUxOkoAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Sy Dzung Nguyen</a> ,¬†Asim Bhatti ,¬†and¬†<a href="https://scholar.google.com/citations?hl=en&amp;user=an_4IJkAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="external nofollow noopener" target="_blank">Chee Peng Lim</a> </div> <div class="periodical"> <em><i><a href="https://www.sciencedirect.com/journal/expert-systems-with-applications" style="color: #FF3636; text-decoration: underline dashed;" rel="external nofollow noopener" target="_blank">Expert Systems with Applications</a></i></em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2109.03219" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/pii/S0957417422022308" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/nhattruongpham/Fruit-CoV" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>COVID-19 is an infectious disease caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). This deadly virus has spread worldwide, leading to a global pandemic since March 2020. A recent variant of SARS-CoV-2 named Delta is intractably contagious and responsible for more than four million deaths globally. Therefore, developing an efficient self-testing service for SARS-CoV-2 at home is vital. In this study, a two-stage vision-based framework, namely Fruit-CoV, is introduced for detecting SARS-CoV-2 infections through recorded cough sounds. Specifically, audio signals are converted into Log-Mel spectrograms, and the EfficientNet-V2 network is used to extract their visual features in the first stage. In the second stage, 14 convolutional layers extracted from the large-scale Pretrained Audio Neural Networks for audio pattern recognition (PANNs) and the Wavegram-Log-Mel-CNN are employed to aggregate feature representations of the Log-Mel spectrograms and the waveform. Finally, the combined features are used to train a binary classifier. In this study, a dataset provided by the AICovidVN 115M Challenge is employed for evaluation. It includes 7,371 recorded cough sounds collected throughout Vietnam, India, and Switzerland. Experimental results indicate that the proposed model achieves an Area Under the Receiver Operating Characteristic Curve (AUC) score of 92.8% and ranks first on the final leaderboard of the AICovidVN 115M Challenge. Our code is publicly available.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">nguyen2023fruit</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fruit-CoV: An efficient vision-based framework for speedy detection and diagnosis of SARS-CoV-2 infections through recorded cough sounds}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nguyen, Long H. and Pham, Nhat Truong and Do, Van Huong and Nguyen, Liu Tai and Nguyen, Thanh Tin and Nguyen, Hai and Nguyen, Ngoc Duy and Nguyen, Thanh Thi and Nguyen, Sy Dzung and Bhatti, Asim and Lim, Chee Peng}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Expert Systems with Applications}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{213}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{119212}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.eswa.2022.119212}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <hr> <hr> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%70%68%61%6D%6E%68%61%74%74%72%75%6F%6E%67.%73%6B%79%6F@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=HybH2XkAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://www.linkedin.com/in/nhattruongpham" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://twitter.com/nhattruong_pham" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> <a href="https://bsky.app/profile/nhattruongpham.bsky.social" title="Bluesky" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-bluesky"></i></a> <a href="https://github.com/nhattruongpham" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.kaggle.com/nhattruongpham" title="Kaggle" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-kaggle"></i></a> <a href="https://www.hackerrank.com/profile/nhattruong_pham" title="HackerRank" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-hackerrank"></i></a> <a href="https://discord.com/users/673453370991837200" title="Discord" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-discord"></i></a> </div> <div class="contact-note"></div> </div> <div style="width: 150px; margin: 0 auto"> <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=RuxfKWte4G6yKP1jx6GjTKLxpqdoMdFm-CPzvceTJNY"></script> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2023 - 2025 Nhat Truong Pham. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. This work is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY-NC-ND 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" alt=""><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" alt=""><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1" alt=""><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nd.svg?ref=chooser-v1" alt=""></a> </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-home",title:"Home",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-news",title:"News",description:"",section:"Navigation",handler:()=>{window.location.href="/news/"}},{id:"nav-publications",title:"Publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-collaborators",title:"Collaborators",description:"",section:"Navigation",handler:()=>{window.location.href="/collaborators/"}},{id:"nav-mentees",title:"Mentees",description:"",section:"Navigation",handler:()=>{window.location.href="/mentees/"}},{id:"nav-repositories",title:"Repositories",description:"",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"nav-cv",title:"CV",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"dropdown-molecules",title:"Molecules",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-dna",title:"DNA",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-rna",title:"RNA",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-peptide",title:"Peptide",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-protein",title:"Protein",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-microbiome",title:"Microbiome",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-imaging",title:"Imaging",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-skku-rs-24",title:"SKKU-RS-24",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-ijcai-24",title:"IJCAI-24",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-acl-24",title:"ACL-24",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-aita-25",title:"AiTA-25",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-bps-am-25",title:"BPS-AM-25",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-aita-cbbl-25",title:"AiTA-CBBL-25",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-acs-nano-aem-25",title:"ACS-Nano-AEM-25",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-isaac-25",title:"ISAAC-25",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"news-one-collaborative-manuscript-entitled-drugormerdti-drug-graphormer-for-drug-target-interaction-prediction-has-been-accepted-for-publication-in-the-computers-in-biology-and-medicine-journal",title:"One collaborative manuscript, entitled \u201cDrugormerDTI: Drug Graphormer for drug\u2013target interaction prediction\u201d, has been...",description:"",section:"News"},{id:"news-one-collaborative-manuscript-entitled-towards-an-efficient-machine-learning-model-for-financial-time-series-forecasting-has-been-accepted-for-publication-in-the-soft-computing-journal",title:"One collaborative manuscript, entitled \u201cTowards an efficient machine learning model for financial time...",description:"",section:"News"},{id:"news-one-manuscript-entitled-hybrid-data-augmentation-and-deep-attention-based-dilated-convolutional-recurrent-neural-networks-for-speech-emotion-recognition-has-been-accepted-for-publication-in-the-expert-systems-with-applications-journal",title:"One manuscript, entitled \u201cHybrid data augmentation and deep attention-based dilated convolutional-recurrent neural networks...",description:"",section:"News"},{id:"news-released-new-officially-personal-website",title:"Released new officially personal website",description:"",section:"News"},{id:"news-one-collaborative-manuscript-entitled-adp-fuse-a-novel-two-layer-machine-learning-predictor-to-identify-antidiabetic-peptides-and-diabetes-types-using-multiview-information-has-been-accepted-for-publication-in-the-computers-in-biology-and-medicine-journal",title:"One collaborative manuscript, entitled \u201cADP-Fuse: A novel two-layer machine learning predictor to identify...",description:"",section:"News"},{id:"news-one-collaborative-manuscript-entitled-comparative-analysis-of-multi-loss-functions-for-enhanced-multi-modal-speech-emotion-recognition-has-been-accepted-for-publication-in-the-2023-14th-international-conference-on-information-and-communication-technology-convergence-ictc",title:"One collaborative manuscript, entitled \u201cComparative analysis of multi-loss functions for enhanced multi-modal speech...",description:"",section:"News"},{id:"news-one-manuscript-entitled-ser-fuse-an-emotion-recognition-application-utilizing-multi-modal-multi-lingual-and-multi-feature-fusion-has-been-accepted-for-publication-in-the-proceedings-of-the-12th-international-symposium-on-information-and-communication-technology",title:"One manuscript, entitled \u201cSER-Fuse: An Emotion Recognition Application Utilizing Multi-Modal, Multi-Lingual, and Multi-Feature...",description:"",section:"News"},{id:"news-one-of-my-very-first-first-author-manuscripts-in-the-field-of-computational-biology-and-bioinformatics-entitled-advancing-the-accuracy-of-sars-cov-2-phosphorylation-site-detection-via-meta-learning-approach-has-been-accepted-for-publication-in-the-briefings-in-bioinformatics-journal",title:"One of my very first first-author manuscripts in the field of Computational Biology...",description:"",section:"News"},{id:"news-our-project-entitled-identification-of-human-2-o-methylation-2om-sites-using-a-hybrid-deep-learning-framework-\ud558\uc774\ube0c\ub9ac\ub4dc-\ub525-\ub7ec\ub2dd-\ud504\ub808\uc784\uc6cc\ud06c\ub97c-\uc0ac\uc6a9\ud55c-\uc778\uac04-2-o-\uba54\ud2f8\ud654-2om-\ubd80\uc704-\uc2dd\ubcc4-has-been-selected-for-the-2023-2nd-k-bds-analysis-infrastructure-utilization-support-program-track-i-large-innovation-research-by-the-korea-bio-data-station-k-bds-korea-institute-of-science-and-technology-information-republic-of-korea",title:"Our project, entitled \u201cIdentification of human 2\u2019-O-methylation (2OM) sites using a hybrid deep...",description:"",section:"News"},{id:"news-two-collaborative-manuscripts-entitled-deep-learning-based-automated-cashier-system-for-bakeries-and-innovative-multi-modal-control-for-surveillance-spider-robot-an-integration-of-voice-and-hand-gesture-recognition-have-been-accepted-for-publication-in-proceedings-of-the-2024-9th-international-conference-on-intelligent-information-technology",title:"Two collaborative manuscripts, entitled \u201cDeep Learning-Based Automated Cashier System for Bakeries\u201d and \u201cInnovative...",description:"",section:"News"},{id:"news-one-manuscript-entitled-h2opred-a-robust-and-efficient-hybrid-deep-learning-model-for-predicting-2-o-methylation-sites-in-human-rna-has-been-accepted-for-publication-in-the-briefings-in-bioinformatics-journal",title:"One manuscript, entitled \u201cH2Opred: a robust and efficient hybrid deep learning model for...",description:"",section:"News"},{id:"news-our-paper-entitled-advancing-the-accuracy-of-sars-cov-2-phosphorylation-site-detection-via-meta-learning-approach-recently-published-in-the-briefings-in-bioinformatics-journal-has-been-cataloged-in-hanbitsa-paper-of-the-biological-research-information-center-bric",title:"Our paper, entitled \u201cAdvancing the accuracy of SARS-CoV-2 phosphorylation site detection via meta-learning...",description:"",section:"News"},{id:"news-my-hanbitsa-interview-regarding-the-recently-published-paper-in-the-briefings-in-bioinformatics-journal-has-been-shared-on-the-biological-research-information-center-bric",title:"My Hanbitsa Interview regarding the recently published paper in the Briefings in Bioinformatics...",description:"",section:"News"},{id:"news-our-paper-entitled-h2opred-a-robust-and-efficient-hybrid-deep-learning-model-for-predicting-2-o-methylation-sites-in-human-rna-recently-published-in-the-briefings-in-bioinformatics-journal-has-been-cataloged-in-hanbitsa-paper-of-the-biological-research-information-center-bric",title:"Our paper, entitled \u201cH2Opred: a robust and efficient hybrid deep learning model for...",description:"",section:"News"},{id:"news-our-research-story-kor-eng-regarding-the-recently-published-papers-in-the-briefings-in-bioinformatics-journal-has-been-highlighted-on-skku-s-research-stories-kor-eng",title:"Our Research Story (KOR/ENG) regarding the recently published papers in the Briefings in...",description:"",section:"News"},{id:"news-our-project-entitled-enhancing-peptide-hla-class-i-binding-prediction-through-siamese-network-based-contrastive-learning-framework-with-feature-fusion-\ud3a9\ud0c0\uc774\ub4dc-hla-class-i-\uacb0\ud569-\uc608\uce21-\uac15\ud654\ub97c-\uc704\ud55c-\ud2b9\uc9d5-\uc735\ud569-\uae30\ubc18-\uc2dc\uc554-\ub124\ud2b8\uc6cc\ud06c-\ub300\uc870-\ud559\uc2b5-\ud504\ub808\uc784\uc6cc\ud06c-has-been-selected-for-the-2024-1st-k-bds-analysis-infrastructure-utilization-support-program-track-i-large-innovation-research-by-the-korea-bio-data-station-k-bds-korea-institute-of-science-and-technology-information-republic-of-korea",title:"Our project, entitled \u201cEnhancing Peptide-HLA Class I Binding Prediction through Siamese Network-Based Contrastive...",description:"",section:"News"},{id:"news-our-project-entitled-enhancing-m6a-rna-modification-prediction-across-cell-lines-and-tissues-using-biological-language-models-and-a-contrastive-learning-framework-has-been-selected-for-the-high-performance-computing-support-project-by-the-korea-association-for-ict-promotion-kait-republic-of-korea",title:"Our project, entitled \u201cEnhancing m6A RNA modification prediction across cell lines and tissues...",description:"",section:"News"},{id:"news-one-manuscript-entitled-ac4c-afl-a-high-precision-identification-of-human-mrna-n4-acetylcytidine-sites-based-on-adaptive-feature-representation-learning-has-been-accepted-for-publication-in-the-molecular-therapy-nucleic-acids-journal",title:"One manuscript, entitled \u201cac4C-AFL: A high-precision identification of human mRNA N4-acetylcytidine sites based...",description:"",section:"News"},{id:"news-one-collaborative-manuscript-entitled-meta-2om-a-multi-classifier-meta-model-for-the-accurate-prediction-of-rna-2-o-methylation-sites-in-human-rna-has-been-accepted-for-publication-in-the-plos-one-journal",title:"One collaborative manuscript, entitled \u201cMeta-2OM: A multi-classifier meta-model for the accurate prediction of...",description:"",section:"News"},{id:"news-one-collaborative-manuscript-entitled-sep-algpro-an-efficient-allergen-prediction-tool-utilizing-traditional-machine-learning-and-deep-learning-techniques-with-protein-language-model-features-has-been-accepted-for-publication-in-the-international-journal-of-biological-macromolecules",title:"One collaborative manuscript, entitled \u201cSEP-AlgPro: An efficient allergen prediction tool utilizing traditional machine...",description:"",section:"News"},{id:"news-one-manuscript-entitled-macppred-2-0-stacked-deep-learning-for-anticancer-peptide-prediction-with-integrated-spatial-and-probabilistic-feature-representations-has-been-accepted-for-publication-in-the-journal-of-molecular-biology",title:"One manuscript, entitled \u201cmACPpred 2.0: Stacked Deep Learning for Anticancer Peptide Prediction with...",description:"",section:"News"},{id:"news-our-project-entitled-predicting-twelve-common-rna-modification-sites-using-advanced-deep-learning-frameworks-with-conventional-and-pre-trained-language-model-features-\uae30\uc874-\ubc0f-\uc0ac\uc804-\ud559\uc2b5\ub41c-\uc5b8\uc5b4-\ubaa8\ub378-\uae30\ubc18-\ud2b9\uc9d5\uc744-\uc0ac\uc6a9\ud558\uc5ec-\uace0\uae09-\ub525\ub7ec\ub2dd-\ud504\ub808\uc784\uc6cc-\ud06c\ub85c-\uc5f4\ub450-\uac1c\uc758-\uc77c\ubc18\uc801\uc778-rna-\uc218\uc815-\ubd80\uc704-\uc608\uce21-has-been-selected-for-the-2024-2nd-k-bds-analysis-infrastructure-utilization-support-program-track-i-large-innovation-research-by-the-korea-bio-data-station-k-bds-korea-institute-of-science-and-technology-information-republic-of-korea",title:"Our project, entitled \u201cPredicting Twelve Common RNA Modification Sites Using Advanced Deep Learning...",description:"",section:"News"},{id:"news-one-manuscript-entitled-hotgpred-enhancing-human-o-linked-threonine-glycosylation-prediction-using-integrated-pretrained-protein-language-model-based-features-and-multi-stage-feature-selection-approach-has-been-accepted-for-publication-in-the-computers-in-biology-and-medicine-journal",title:"One manuscript, entitled \u201cHOTGpred: Enhancing human O-linked threonine glycosylation prediction using integrated pretrained...",description:"",section:"News"},{id:"news-two-manuscripts-entitled-mol2lang-vlm-vision-and-text-guided-generative-pre-trained-language-models-for-advancing-molecule-captioning-through-multimodal-fusion-and-lang2mol-diff-a-diffusion-based-generative-model-for-language-to-molecule-translation-leveraging-selfies-representation-have-been-accepted-for-publication-in-the-proceedings-of-the-1st-workshop-on-language-molecules-l-m-2024",title:"Two manuscripts, entitled \u201cMol2Lang-VLM: Vision- and Text-Guided Generative Pre-trained Language Models for Advancing...",description:"",section:"News"},{id:"news-two-collaborative-manuscripts-entitled-federated-learning-with-u-net-for-brain-tumor-segmentation-impact-of-client-numbers-and-data-distribution-and-towards-real-time-vietnamese-traffic-sign-recognition-on-embedded-systems-have-been-accepted-for-publication-in-the-2024-15th-international-conference-on-information-and-communication-technology-convergence-ictc",title:"Two collaborative manuscripts, entitled \u201cFederated Learning with U-Net for Brain Tumor Segmentation: Impact...",description:"",section:"News"},{id:"news-our-project-entitled-accurate-liver-pathology-identification-via-dual-stream-graph-convolutional-networks-\uc774\uc911-\uc2a4\ud2b8\ub9bc-\uadf8\ub798\ud504-\ud569\uc131\uacf1-\uc2e0\uacbd\ub9dd\uc744-\ud1b5\ud55c-\uc815\ud655\ud55c-\uac04-\ubcd1\ub9ac-\uc2dd\ubcc4-has-been-selected-for-the-2024-3rd-k-bds-analysis-infrastructure-utilization-support-program-track-i-large-innovation-research-by-the-korea-bio-data-station-k-bds-korea-institute-of-science-and-technology-information-republic-of-korea",title:"Our project, entitled \u201cAccurate Liver Pathology Identification via Dual-stream Graph Convolutional Networks (\uc774\uc911...",description:"",section:"News"},{id:"news-one-collaborative-manuscript-entitled-hubert-clap-contrastive-learning-based-multimodal-emotion-recognition-using-self-alignment-approach-has-been-accepted-for-publication-in-the-mmasia-24-proceedings-of-the-6th-acm-international-conference-on-multimedia-in-asia",title:"One collaborative manuscript, entitled \u201cHuBERT-CLAP: Contrastive Learning-Based Multimodal Emotion Recognition using Self-Alignment Approach\u201d,...",description:"",section:"News"},{id:"news-one-co-authored-manuscript-entitled-mst-m6a-a-novel-multi-scale-transformer-based-framework-for-accurate-prediction-of-m6a-modification-sites-across-diverse-cellular-contexts-has-been-accepted-for-publication-in-the-journal-of-molecular-biology",title:"One co-authored manuscript, entitled \u201cMST-m6A: A Novel Multi-Scale Transformer-based Framework for Accurate Prediction...",description:"",section:"News"},{id:"news-successfully-completed-the-preliminary-defense-for-my-ph-d-dissertation-and-became-a-ph-d-candidate",title:"Successfully completed the Preliminary Defense for my Ph.D. Dissertation and became a Ph.D....",description:"",section:"News"},{id:"news-one-manuscript-entitled-leveraging-deep-transfer-learning-and-explainable-ai-for-accurate-covid-19-diagnosis-insights-from-a-multi-national-chest-ct-scan-study-has-been-accepted-for-publication-in-the-computers-in-biology-and-medicine-journal",title:"One manuscript, entitled \u201cLeveraging deep transfer learning and explainable AI for accurate COVID-19...",description:"",section:"News"},{id:"news-received-the-skku-bk21-innovative-research-scholarship-\uad50\uc721\uc5f0\uad6c\ub2e8-\uc7a5\ud559\ud601\uc2e0-skku-bk21-\ud601\uc2e0\uc5f0\uad6c-\uc7a5\ud559\uae08",title:"Received the SKKU BK21 Innovative Research Scholarship (\uad50\uc721\uc5f0\uad6c\ub2e8 \uc7a5\ud559\ud601\uc2e0 (SKKU BK21 \ud601\uc2e0\uc5f0\uad6c \uc7a5\ud559\uae08))...",description:"",section:"News"},{id:"news-one-manuscript-entitled-dogpred-a-novel-deep-learning-framework-for-accurate-identification-of-human-o-linked-threonine-glycosylation-sites-has-been-accepted-for-publication-in-the-journal-of-molecular-biology",title:"One manuscript, entitled \u201cDOGpred: A Novel Deep Learning Framework for Accurate Identification of...",description:"",section:"News"},{id:"news-one-collaborative-manuscript-entitled-memocmt-multimodal-emotion-recognition-using-cross-modal-transformer-based-feature-fusion-has-been-accepted-for-publication-in-the-scientific-reports-journal",title:"One collaborative manuscript, entitled \u201cMemoCMT: multimodal emotion recognition using cross-modal transformer-based feature fusion\u201d,...",description:"",section:"News"},{id:"news-received-the-caregen-chung-yong-ji-scholarship-\ucf00\uc5b4\uc820\uc815\uc6a9\uc9c0\uc7a5\ud559\uae08-\uc77c\ubc18\uc6d0",title:"Received the Caregen Chung Yong-ji Scholarship (\ucf00\uc5b4\uc820\uc815\uc6a9\uc9c0\uc7a5\ud559\uae08(\uc77c\ubc18\uc6d0))",description:"",section:"News"},{id:"news-received-the-university-innovation-awards-and-living-expenses-\ub300\ud559\ud601\uc2e0-\ud3ec\uc0c1\ubc0f\uc0dd\ud65c\ube44-\uc77c\ubc18\uc6d0",title:"Received the University Innovation - Awards and Living Expenses (\ub300\ud559\ud601\uc2e0-\ud3ec\uc0c1\ubc0f\uc0dd\ud65c\ube44(\uc77c\ubc18\uc6d0))",description:"",section:"News"},{id:"news-one-co-authored-manuscript-entitled-xmolcap-advancing-molecular-captioning-through-multimodal-fusion-and-explainable-graph-neural-networks-has-been-accepted-for-publication-in-the-ieee-journal-of-biomedical-and-health-informatics",title:"One co-authored manuscript, entitled \u201cXMolCap: Advancing Molecular Captioning through Multimodal Fusion and Explainable...",description:"",section:"News"},{id:"news-one-manuscript-entitled-hypeptox-fuse-an-interpretable-hybrid-framework-for-accurate-peptide-toxicity-prediction-fusing-protein-language-model-based-embeddings-with-conventional-descriptors-has-been-accepted-for-publication-in-the-journal-of-pharmaceutical-analysis",title:"One manuscript, entitled \u201cHyPepTox-Fuse: An interpretable hybrid framework for accurate peptide toxicity prediction...",description:"",section:"News"},{id:"news-our-project-entitled-identification-of-dna-6ma-modification-sites-using-a-genomic-language-model-based-on-local-and-global-feature-representation-learning-\uc9c0\uc5ed-\ubc0f-\uc804\uc5ed-\ud2b9\uc9d5-\ud45c\ud604-\ud559\uc2b5-\uae30\ubc18-\uc720\uc804\uccb4-\uc5b8\uc5b4-\ubaa8\ub378\uc744-\ud65c\uc6a9\ud55c-dna-6ma-\ubcc0\ud615-\uc704\uce58-\uc2dd\ubcc4-has-been-selected-for-the-2025-2nd-k-bds-analysis-infrastructure-utilization-support-program-track-i-large-innovation-research-by-the-korea-bio-data-station-k-bds-korea-institute-of-science-and-technology-information-republic-of-korea",title:"Our project, entitled \u201cIdentification of DNA 6mA Modification Sites Using A Genomic Language...",description:"",section:"News"},{id:"news-one-manuscript-entitled-xbittert5-an-explainable-transformer-based-framework-with-multimodal-inputs-for-identifying-bitter-taste-peptides-has-been-accepted-for-publication-in-the-journal-of-cheminformatics",title:"One manuscript, entitled \u201cxBitterT5: an explainable transformer-based framework with multimodal inputs for identifying...",description:"",section:"News"},{id:"news-my-skkuzine-interview-regarding-the-foreigner-s-life-at-sungkyunkwan-university-section-has-been-shared-on-the-sungkyunkwan-webzine-skkuzine",title:"My SKKUZINE Interview regarding the Foreigner\u2019s Life at Sungkyunkwan University section has been...",description:"",section:"News"},{id:"news-our-project-entitled-multiple-prediction-of-rna-modification-sites-using-rna-foundation-models-and-transformer-fusion-rna-\ud30c\uc6b4\ub370\uc774\uc158-\ubaa8\ub378\ub4e4\uacfc-\ud2b8\ub79c\uc2a4\ud3ec\uba38-\uc735\ud569\uc744-\ud65c\uc6a9\ud55c-rna-\ubcc0\ud615-\ubd80\uc704-\ub2e4\uc911-\uc608\uce21-has-been-selected-for-the-2025-3rd-k-bds-analysis-infrastructure-utilization-support-program-track-i-large-innovation-research-by-the-korea-bio-data-station-k-bds-korea-institute-of-science-and-technology-information-republic-of-korea",title:"Our project, entitled \u201cMultiple prediction of RNA modification sites using RNA foundation models...",description:"",section:"News"},{id:"news-one-collaborative-manuscript-entitled-federated-semi-supervised-fixmatch-enhancing-cutmix-for-medical-image-segmentation-has-been-accepted-for-publication-in-the-2025-ieee-international-conference-on-big-data-ieee-bigdata",title:"One collaborative manuscript, entitled \u201cFederated Semi-Supervised FixMatch: Enhancing CutMix for Medical Image Segmentation\u201d,...",description:"",section:"News"},{id:"news-one-co-authored-manuscript-entitled-mulaqua-an-interpretable-multimodal-deep-learning-framework-for-identifying-pmt-vpvm-substances-in-drinking-water-has-been-accepted-for-publication-in-the-journal-of-hazardous-materials",title:"One co-authored manuscript, entitled \u201cMulaqua: An interpretable multimodal deep learning framework for identifying...",description:"",section:"News"},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%70%68%61%6D%6E%68%61%74%74%72%75%6F%6E%67.%73%6B%79%6F@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=HybH2XkAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/nhattruongpham","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/nhattruongpham","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/nhattruong_pham","_blank")}},{id:"socials-kaggle",title:"Kaggle",section:"Socials",handler:()=>{window.open("https://www.kaggle.com/nhattruongpham","_blank")}},{id:"socials-bluesky",title:"Bluesky",section:"Socials",handler:()=>{window.open("https://bsky.app/profile/nhattruongpham.bsky.social","_blank")}},{id:"socials-discord",title:"Discord",section:"Socials",handler:()=>{window.open("https://discord.com/users/673453370991837200","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>